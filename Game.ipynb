{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set it up only when you dont have a venv already.\n",
    "# from venv_script import activate_venv\n",
    "# activate_venv()\n",
    "\n",
    "# !pip install pygame\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/michal.maslowski/Documents/GitHub/OvercookedAI-coop\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import importlib\n",
    "import tensorflow as tf\n",
    "\n",
    "# from training_algorithm import Misha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    details = tf.config.experimental.get_device_details(gpu)\n",
    "    print(f\"GPU: {gpu.name}, Memory Limit: {details['memory_limit']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michal.maslowski/Documents/GitHub/OvercookedAI-coop/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n",
      "2.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:33:04.297 Python[8055:59961] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset the game\n",
      "1/1 [==============================] - 0s 459ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 269\u001b[0m\n\u001b[1;32m    266\u001b[0m             clock\u001b[39m.\u001b[39mtick(\u001b[39m60\u001b[39m)   \n\u001b[1;32m    268\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (number_of_games):\n\u001b[0;32m--> 269\u001b[0m     game()    \n\u001b[1;32m    271\u001b[0m pygame\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mquit()\n\u001b[1;32m    272\u001b[0m pygame\u001b[39m.\u001b[39mquit()\n",
      "Cell \u001b[0;32mIn[3], line 230\u001b[0m, in \u001b[0;36mgame\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m learning \u001b[39mand\u001b[39;00m (tick \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m    228\u001b[0m     rewards \u001b[39m=\u001b[39m get_rewards()\n\u001b[0;32m--> 230\u001b[0m     add_memory(state[\u001b[39m0\u001b[39;49m], state[\u001b[39m1\u001b[39;49m], former_state[\u001b[39m0\u001b[39;49m], former_state[\u001b[39m1\u001b[39;49m], action_idxs, rewards \u001b[39m-\u001b[39;49m former_rewards)\n\u001b[1;32m    232\u001b[0m     former_rewards \u001b[39m=\u001b[39m rewards\n\u001b[1;32m    233\u001b[0m     draw() \n",
      "File \u001b[0;32m~/Documents/GitHub/OvercookedAI-coop/training_algorithm.py:30\u001b[0m, in \u001b[0;36madd_memory\u001b[0;34m(vis_state, num_state, final_vis_state, final_num_state, action_idxs, reward, gamma)\u001b[0m\n\u001b[1;32m     27\u001b[0m action_idxs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(action_idxs, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39m#Add: state, indices of actions, a reward to the memory buffer\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m vis_state_buffer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack((vis_state_buffer, vis_state))\n\u001b[1;32m     31\u001b[0m num_state_buffer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack((num_state_buffer, num_state))\n\u001b[1;32m     32\u001b[0m action_idxs_buffer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack((action_idxs_buffer, action_idxs))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "misha_playing = True #Bot vs human play\n",
    "learning = True #Specifies whether the experience is added to the replay buffer\n",
    "\n",
    "#if not learning:\n",
    "if learning:\n",
    "    from training_algorithm import add_memory, train_Misha, Misha\n",
    "    time_training = np.array([])\n",
    "    time_actions = np.array([])\n",
    "    total_time = np.array([])\n",
    "    losses = np.array([])\n",
    "    times_per_action = np.array([])\n",
    "    number_updates = 64 #The power of 2 that is the closest to the time contraints on Kaggle. No_of_games = 64\n",
    "    ticks_per_game = 2**14 #Divisor of 30*64*128 which is the closest to a 5-minute gameplay (actual time: ~4.5 mins)\n",
    "    ticks_per_update = 30*64*128\n",
    "    number_of_games = (number_updates * ticks_per_update)//ticks_per_game\n",
    "    update_count = 0\n",
    "    \n",
    "    \n",
    "else:\n",
    "    number_of_games = 2\n",
    "    \n",
    "    if misha_playing:\n",
    "        from tensorflow import keras\n",
    "        Misha = keras.saving.load_model(\"Misha.keras\", safe_mode=False)\n",
    "        \n",
    "pygame.init()    \n",
    "screen = pygame.display.set_mode((800, 600))\n",
    "\n",
    "time_per_game = int(input(\"Please enter the length of the game, in seconds (default: 180)\")) if not learning else 99999999\n",
    "\n",
    "all_ticks = 0\n",
    "\n",
    "def game():\n",
    "    global all_ticks\n",
    "    \n",
    "    import Objects\n",
    "    importlib.reload(Objects)\n",
    "    import Foods\n",
    "    importlib.reload(Foods)\n",
    "    import Player\n",
    "    importlib.reload(Player)\n",
    "    import Board\n",
    "    importlib.reload(Board)\n",
    "    import constants\n",
    "    importlib.reload(constants)\n",
    "    \n",
    "    from Objects import Walls, Floors, CBoards, Fryers\n",
    "    from Foods import Resources, Fish, Potato, Plate\n",
    "    from Player import Players, Player1, Player2, player1_controls, player2_controls\n",
    "    from Foods import Menu\n",
    "    from constants import START_X, END_X, START_Y, END_Y\n",
    "    \n",
    "    print(\"reset the game\")\n",
    "    running = True\n",
    "    clock = pygame.time.Clock()\n",
    "    tick = 0\n",
    "    game_score = 0\n",
    "    \n",
    "    actions = None\n",
    "    former_state = None\n",
    "    rewards = None\n",
    "    former_rewards = 0.\n",
    "    start_time = pygame.time.get_ticks()\n",
    "    \n",
    "    def update(actions):\n",
    "        elapsed_time = (pygame.time.get_ticks() - start_time) / 1000\n",
    "        if(elapsed_time < time_per_game):\n",
    "            Players.update(actions)\n",
    "            CBoards.update()\n",
    "            Fryers.update()\n",
    "            Menu.update()\n",
    "\n",
    "\n",
    "        else:\n",
    "            #Game finished; display a large \"GAME OVER\" sign over a frozen frame\n",
    "            font = pygame.font.SysFont(\"comicsansms\", 100)\n",
    "            game_over_surface = font.render(\"GAME OVER\", True, (255, 0, 0))\n",
    "            game_over_rect = game_over_surface.get_rect(center=((START_X+END_X)//2, (START_Y + END_Y)//2))\n",
    "            \n",
    "            score_text = f\"Final Score: {Menu.game_score}\"\n",
    "            score_surface = font.render(score_text, True, (0, 0, 0))\n",
    "            score_rect = score_surface.get_rect(center=((START_X + END_X) // 2, (START_Y + END_Y) // 2 + 100))\n",
    "            \n",
    "            screen.blit(game_over_surface, game_over_rect)\n",
    "            screen.blit(score_surface, score_rect)\n",
    "\n",
    "    def q2idx(tick, learning):\n",
    "        q_values = get_q_values(tick, learning)\n",
    "\n",
    "        \n",
    "        p1_values = q_values[0:5]\n",
    "        p1_idx = p1_values.argmax() #Get the action from player 1 that maximizes the q value\n",
    "        \n",
    "        \n",
    "        p1_action_possible = not (Player1.action_possible()[\"action\"] == None)\n",
    "        if (p1_idx == 4 and (not p1_action_possible)):\n",
    "            p1_idx = p1_values[0:4].argmax() #Get the 2nd best action if an action is the best one and isn't possible\n",
    "        \n",
    "        p2_values = q_values[5:10]\n",
    "        p2_idx = p2_values.argmax() #Get the action from player 1 that maximizes the q value\n",
    "        \n",
    "        p2_action_possible = not (Player2.action_possible()[\"action\"] == None)\n",
    "        if (p2_idx == 4 and (not p2_action_possible)):\n",
    "            p2_idx = p2_values[0:4].argmax() #Get the 2nd best action if an action is the best one and isn't possible\n",
    "        \n",
    "        return np.array([p1_idx, p2_idx])\n",
    "    \n",
    "    def idx2key(idxs):\n",
    "        p1_idx = idxs[0]\n",
    "        p2_idx = idxs[1]\n",
    "        \n",
    "        keys = [key for key in dir(pygame) if key.startswith('K_')]\n",
    "        keys_dict = {getattr(pygame, key): False for key in keys}\n",
    "        \n",
    "        keys_dict[list(player1_controls.values())[p1_idx]] = True\n",
    "        keys_dict[list(player2_controls.values())[p2_idx]] = True\n",
    "        \n",
    "        return keys_dict\n",
    "    \n",
    "    def draw():\n",
    "        screen.fill((255, 255, 255)) \n",
    "        Floors.draw(screen)\n",
    "        Walls.draw(screen)\n",
    "        Fryers.draw(screen)\n",
    "        Resources.draw(screen)\n",
    "        Players.draw(screen)\n",
    "        Menu.draw(screen)\n",
    "    \n",
    "    def get_rewards():\n",
    "        '''\n",
    "        Computes the total amount of rewards for the current game state. \n",
    "        Raw food needed to finish the menu is worth 5 points, \n",
    "        Cut food on the menu - 15 points \n",
    "        Fried food on the menu - 25 points\n",
    "        Plate - 50 points\n",
    "        Preparing a dish from the menu - half the points of giving the order \n",
    "        Fish - 500 points\n",
    "        Fish and Chips - 1000 points\n",
    "        '''\n",
    "        \n",
    "        raw_coeff = 50\n",
    "        chopped_coeff = 150\n",
    "        fried_coeff = 250\n",
    "        plate_coeff = 500\n",
    "        \n",
    "        rewards = Menu.game_score*10\n",
    "        \n",
    "        food_categories = [(\"Fish\", Fish), (\"Potato\", Potato)]\n",
    "        for name, cls in food_categories:\n",
    "            food_on_menu = sum([dish.ingredients_dict[name] for dish in Menu.queue])\n",
    "            fried_food = len([food for food in Resources if (isinstance(food, cls) and food.fried)])\n",
    "            chopped_food = len([food for food in Resources if (isinstance(food, cls) and food.chopped and not food.fried)])\n",
    "            raw_food = len([food for food in Resources if (isinstance(food, cls) and not food.chopped and not food.fried)])\n",
    "            \n",
    "            remaining_food_on_menu = food_on_menu\n",
    "            rewards += fried_coeff * min(food_on_menu, fried_food)\n",
    "            \n",
    "            remaining_food_on_menu -= min(food_on_menu, fried_food)\n",
    "            rewards += chopped_coeff * min(chopped_food, remaining_food_on_menu) \n",
    "            \n",
    "            remaining_food_on_menu -= min(chopped_food, remaining_food_on_menu) \n",
    "            rewards += raw_coeff * min(raw_food, remaining_food_on_menu)\n",
    "        \n",
    "        plates = len([food for food in Resources if isinstance(food, Plate)])\n",
    "        rewards += plate_coeff * min(plates, len(Menu.queue))\n",
    "        \n",
    "        return float(rewards)\n",
    "\n",
    "    def get_q_values(tick, learning):\n",
    "        def eps_function(tick):\n",
    "            #Epsilon function will start at (nearly) 1 and exponentially decrease to 0.1\n",
    "            return 0.1 + 0.9 * np.exp(- 1e-6 * tick)\n",
    "\n",
    "        is_random = random() < eps_function(tick)\n",
    "        if (is_random and learning):\n",
    "            #Randomizes q-values for each move. Equivalent to picking random moves, except that action if possible is preferred\n",
    "            q_values = np.random.rand(10)\n",
    "            q_values[4] = q_values.max() + 1 #Set q_value of action for player 1 to max \n",
    "            q_values[9] = q_values.max() + 1 #Set q_value of action for player 2 to max \n",
    "            \n",
    "        else:\n",
    "            q_values = Misha.predict(get_state())\n",
    "            q_values = q_values[0] #Get rid of the batch_size dimension: goes from (1, 10) to (10,) \n",
    "            \n",
    "        return q_values\n",
    "    \n",
    "    def get_state():\n",
    "        '''\n",
    "        Returns the list of:\n",
    "        - visual_data - normalized pixel values of the screen\n",
    "        - numerical_data, containing in respective order:\n",
    "            - the state of the Menu (see: Menu.get_state())\n",
    "            - the state of Player 1's and Player 2's hands (see: Player.get_state())\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        visual_data = pygame.surfarray.array3d(screen)\n",
    "        visual_data = np.transpose(visual_data, (1, 0, 2)) #Change from width, height, color channel to height, width, color channel\n",
    "        visual_data = visual_data[START_Y - Menu.height: END_Y, START_X:END_X]\n",
    "        visual_data = visual_data / 255. #Normalize pixels from 0 to 1 for easier training\n",
    "        visual_data = np.expand_dims(visual_data, axis=0)\n",
    "\n",
    "        numerical_data = np.concatenate((Menu.get_state(), Player1.get_state(), Player2.get_state()))\n",
    "        numerical_data = numerical_data.astype(float)\n",
    "        numerical_data = np.expand_dims(numerical_data, axis=0)\n",
    "        \n",
    "        return [visual_data, numerical_data]\n",
    "\n",
    "    while running:\n",
    "        total_start_time = time.time()\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "                break\n",
    "\n",
    "        if(not running):\n",
    "            break\n",
    "        \n",
    "        if misha_playing and (tick % 30 == 0):\n",
    "            start_time = time.time()\n",
    "            state = get_state()\n",
    "            action_idxs = q2idx(tick, learning)\n",
    "            actions = idx2key(action_idxs)\n",
    "            if learning and (tick != 0):\n",
    "                rewards = get_rewards()\n",
    "                \n",
    "                add_memory(state[0], state[1], former_state[0], former_state[1], action_idxs, rewards - former_rewards)\n",
    "            \n",
    "                former_rewards = rewards\n",
    "                draw() \n",
    "                \n",
    "            former_state = state   \n",
    "            if learning:\n",
    "                np.append(times_per_action, time.time() - start_time)     \n",
    "        \n",
    "        if learning and ((all_ticks + 1) % (ticks_per_update) == 0): \n",
    "            start_training_time = time.time()\n",
    "            losses_epoch, _ = train_Misha() \n",
    "            losses = np.append(losses, losses_epoch)\n",
    "            # time_training = np.append(time_training, time.time()-start_training_time)\n",
    "            # time_actions = np.append(time_actions, times_per_action.sum())\n",
    "            # total_time = np.append(total_time, time.time() - total_start_time)\n",
    "            # np.save('time_training.npy', time_training)\n",
    "            # np.save('time_actions.npy', time_actions)\n",
    "            # np.save('total_time.npy', total_time)\n",
    "            # np.save('time_saving.npy', time_saving)\n",
    "            # np.save('losses.npy', losses)\n",
    "            start_time = pygame.time.get_ticks() #Reset the clock\n",
    "            print(\"training time: \", time.time() - start_training_time)\n",
    "        \n",
    "        if (learning and ((tick+1)%ticks_per_game == 0)):\n",
    "            running = False    \n",
    "        \n",
    "        if not misha_playing:\n",
    "            actions = pygame.key.get_pressed()\n",
    "            \n",
    "        if ((all_ticks+1) % 1e5 == 0):\n",
    "            if (tick != 0):\n",
    "                e5_time = time.time()\n",
    "                print(\"1e5 ticks made in \", e5_time - former_e5_time, \". At this pace, getting to theupdate takes \", (e5_time - former_e5_time)*number_updates/1e5/1e3, \" seconds\")\n",
    "                \n",
    "            former_e5_time = time.time()\n",
    "\n",
    "        all_ticks += 1\n",
    "\n",
    "        tick += 1\n",
    "        all_ticks += 1\n",
    "        \n",
    "        draw()    \n",
    "        update(actions) \n",
    "        \n",
    "        if not learning:\n",
    "            pygame.display.flip()\n",
    "            clock.tick(60)   \n",
    "\n",
    "for _ in range (number_of_games):\n",
    "    game()    \n",
    "        \n",
    "pygame.display.quit()\n",
    "pygame.quit()\n",
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
