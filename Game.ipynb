{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.9.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# !pip install pygame\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 12:57:04.591 Python[77213:6191972] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    }
   ],
   "source": [
    "from Objects import Walls, Floors, CBoards, Fryers\n",
    "from Foods import Resources, Fish, Potato, Plate\n",
    "from Player import Players, Player1, Player2, player1_controls, player2_controls\n",
    "from Foods import Menu\n",
    "from random import random\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('/Users/michal.maslowski/Documents/GitHub/OvercookedAI-coop')\n",
    "\n",
    "# from training_algorithm import Misha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import START_X, END_X, START_Y, END_Y\n",
    "\n",
    "def get_state():\n",
    "    '''\n",
    "    Returns the list of:\n",
    "    - visual_data - normalized pixel values of the screen\n",
    "    - numerical_data, containing in respective order:\n",
    "        - the state of the Menu (see: Menu.get_state())\n",
    "        - the state of Player 1's and Player 2's hands (see: Player.get_state())\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    visual_data = pygame.surfarray.array3d(screen)\n",
    "    visual_data = np.transpose(visual_data, (1, 0, 2)) #Change from width, height, color channel to height, width, color channel\n",
    "    visual_data = visual_data[START_Y - Menu.height: END_Y, START_X:END_X]\n",
    "    visual_data = visual_data / 255. #Normalize pixels from 0 to 1 for easier training\n",
    "    visual_data = np.expand_dims(visual_data, axis=0)\n",
    "\n",
    "    numerical_data = np.concatenate((Menu.get_state(), Player1.get_state(), Player2.get_state()))\n",
    "    numerical_data = numerical_data.astype(float)\n",
    "    numerical_data = np.expand_dims(numerical_data, axis=0)\n",
    "    \n",
    "    return [visual_data, numerical_data]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rewards():\n",
    "    '''\n",
    "    Computes the total amount of rewards for the current game state. \n",
    "    Raw food needed to finish the menu is worth 5 points, \n",
    "    Cut food on the menu - 15 points \n",
    "    Fried food on the menu - 25 points\n",
    "    Plate - 50 points\n",
    "    Preparing a dish from the menu - half the points of giving the order \n",
    "    Fish - 500 points\n",
    "    Fish and Chips - 1000 points\n",
    "    '''\n",
    "    \n",
    "    raw_coeff = 50\n",
    "    chopped_coeff = 150\n",
    "    fried_coeff = 250\n",
    "    plate_coeff = 500\n",
    "    \n",
    "    rewards = Menu.game_score*10\n",
    "    \n",
    "    food_categories = [(\"Fish\", Fish), (\"Potato\", Potato)]\n",
    "    for name, cls in food_categories:\n",
    "        food_on_menu = sum([dish.ingredients_dict[name] for dish in Menu.queue])\n",
    "        fried_food = len([food for food in Resources if (isinstance(food, cls) and food.fried)])\n",
    "        chopped_food = len([food for food in Resources if (isinstance(food, cls) and food.chopped and not food.fried)])\n",
    "        raw_food = len([food for food in Resources if (isinstance(food, cls) and not food.chopped and not food.fried)])\n",
    "        \n",
    "        remaining_food_on_menu = food_on_menu\n",
    "        rewards += fried_coeff * min(food_on_menu, fried_food)\n",
    "        \n",
    "        remaining_food_on_menu -= min(food_on_menu, fried_food)\n",
    "        rewards += chopped_coeff * min(chopped_food, remaining_food_on_menu) \n",
    "        \n",
    "        remaining_food_on_menu -= min(chopped_food, remaining_food_on_menu) \n",
    "        rewards += raw_coeff * min(raw_food, remaining_food_on_menu)\n",
    "    \n",
    "    plates = len([food for food in Resources if isinstance(food, Plate)])\n",
    "    rewards += plate_coeff * min(plates, len(Menu.queue))\n",
    "    \n",
    "    return float(rewards)\n",
    "    \n",
    "    #TO-DO HERE: ADD INTERMEDIATE REWARDS FOR HAVING A NEAR-READY DISH\n",
    "    #Get the dict of plate and the dish and see if any match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw():\n",
    "    screen.fill((255, 255, 255)) \n",
    "    Floors.draw(screen)\n",
    "    Walls.draw(screen)\n",
    "    Resources.draw(screen)\n",
    "    Players.draw(screen)\n",
    "    Menu.draw(screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_values(tick, learning):\n",
    "    def eps_function(tick):\n",
    "        #Epsilon function will start at (nearly) 1 and exponentially decrease to 0.1\n",
    "        return 0.1 + 0.9 * np.exp(- 1e-6 * tick)\n",
    "\n",
    "    is_random = random() < eps_function(tick)\n",
    "    if (is_random and learning):\n",
    "        #Randomizes q-values for each move. Equivalent to picking random moves, except that action if possible is preferred\n",
    "        q_values = np.random.rand(10)\n",
    "        q_values[4] = q_values.max() + 1 #Set q_value of action for player 1 to max \n",
    "        q_values[9] = q_values.max() + 1 #Set q_value of action for player 2 to max \n",
    "        \n",
    "    else:\n",
    "        q_values = Misha.predict(get_state())\n",
    "        q_values = q_values[0] #Get rid of the batch_size dimension: goes from (1, 10) to (10,) \n",
    "        \n",
    "    return q_values\n",
    "        \n",
    "    \n",
    "\n",
    "def q2idx(tick, learning):\n",
    "    q_values = get_q_values(tick, learning)\n",
    "\n",
    "    \n",
    "    p1_values = q_values[0:5]\n",
    "    p1_idx = p1_values.argmax() #Get the action from player 1 that maximizes the q value\n",
    "    \n",
    "    \n",
    "    p1_action_possible = not (Player1.action_possible()[\"action\"] == None)\n",
    "    if (p1_idx == 4 and (not p1_action_possible)):\n",
    "        p1_idx = p1_values[0:4].argmax() #Get the 2nd best action if an action is the best one and isn't possible\n",
    "    \n",
    "    p2_values = q_values[5:10]\n",
    "    p2_idx = p2_values.argmax() #Get the action from player 1 that maximizes the q value\n",
    "    \n",
    "    p2_action_possible = not (Player2.action_possible()[\"action\"] == None)\n",
    "    if (p2_idx == 4 and (not p2_action_possible)):\n",
    "        p2_idx = p2_values[0:4].argmax() #Get the 2nd best action if an action is the best one and isn't possible\n",
    "    \n",
    "    return np.array([p1_idx, p2_idx])\n",
    "    \n",
    "\n",
    "def idx2key(idxs):\n",
    "    p1_idx = idxs[0]\n",
    "    p2_idx = idxs[1]\n",
    "    \n",
    "    keys = [key for key in dir(pygame) if key.startswith('K_')]\n",
    "    keys_dict = {getattr(pygame, key): False for key in keys}\n",
    "    \n",
    "    keys_dict[list(player1_controls.values())[p1_idx]] = True\n",
    "    keys_dict[list(player2_controls.values())[p2_idx]] = True\n",
    "    \n",
    "    return keys_dict\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "running = True\n",
    "clock = pygame.time.Clock()\n",
    "tick = 0\n",
    "game_score = 0\n",
    "\n",
    "misha_playing = True #Bot vs human play\n",
    "learning = False #Specifies whether the experience is added to the replay buffer\n",
    "\n",
    "#if not learning:\n",
    "if learning:\n",
    "    from training_algorithm import add_memory, train_Misha, Misha\n",
    "    time_training = np.array([])\n",
    "    time_actions = np.array([])\n",
    "    total_time = np.array([])\n",
    "    losses = np.array([])\n",
    "    \n",
    "else:\n",
    "    if misha_playing:\n",
    "        from tensorflow import keras\n",
    "        Misha = keras.saving.load_model(\"Misha.keras\", safe_mode=False)\n",
    "        \n",
    "pygame.init()    \n",
    "screen = pygame.display.set_mode((800, 600))\n",
    "\n",
    "#Defining global variables for use later\n",
    "actions = None\n",
    "former_state = None\n",
    "rewards = None\n",
    "former_rewards = 0.\n",
    "\n",
    "time_per_game = int(input(\"Please enter the length of the game, in seconds (default: 180)\")) if not learning else 99999999\n",
    "start_time = pygame.time.get_ticks()\n",
    "\n",
    "\n",
    "def update(actions):\n",
    "    elapsed_time = (pygame.time.get_ticks() - start_time) / 1000\n",
    "    if(elapsed_time < time_per_game):\n",
    "        Players.update(actions)\n",
    "        CBoards.update()\n",
    "        Fryers.update()\n",
    "        Menu.update()\n",
    "\n",
    "\n",
    "    else:\n",
    "        #Game finished; display a large \"GAME OVER\" sign over a frozen frame\n",
    "        font = pygame.font.SysFont(\"comicsansms\", 100)\n",
    "        game_over_surface = font.render(\"GAME OVER\", True, (255, 0, 0))\n",
    "        game_over_rect = game_over_surface.get_rect(center=((START_X+END_X)//2, (START_Y + END_Y)//2))\n",
    "        \n",
    "        score_text = f\"Final Score: {Menu.game_score}\"\n",
    "        score_surface = font.render(score_text, True, (0, 0, 0))\n",
    "        score_rect = score_surface.get_rect(center=((START_X + END_X) // 2, (START_Y + END_Y) // 2 + 100))\n",
    "        \n",
    "        screen.blit(game_over_surface, game_over_rect)\n",
    "        screen.blit(score_surface, score_rect)\n",
    "\n",
    "\n",
    "times_per_action = np.array([])\n",
    "while running:\n",
    "    total_start_time = time.time()\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "            break\n",
    "\n",
    "    if(not running):\n",
    "        break\n",
    "    \n",
    "    \n",
    "    if misha_playing and (tick % 30 == 0):\n",
    "        start_time = time.time()\n",
    "        state = get_state()\n",
    "        action_idxs = q2idx(tick, learning)\n",
    "        actions = idx2key(action_idxs)\n",
    "        if learning and (tick != 0):\n",
    "            rewards = get_rewards()\n",
    "            \n",
    "            add_memory(state[0], state[1], former_state[0], former_state[1], action_idxs, rewards - former_rewards)\n",
    "        \n",
    "            former_rewards = rewards\n",
    "            draw() \n",
    "            \n",
    "        former_state = state   \n",
    "        np.append(times_per_action, time.time() - start_time)     \n",
    "    \n",
    "    if learning and ((tick + 1) % (30*64*128) == 0): \n",
    "        start_training_time = time.time()\n",
    "        losses_epoch, time_saving = train_Misha() \n",
    "        losses = np.append(losses, losses_epoch)\n",
    "        time_training = np.append(time_training, time.time()-start_training_time)\n",
    "        time_actions = np.append(time_actions, times_per_action.sum())\n",
    "        total_time = np.append(total_time, time.time() - total_start_time)\n",
    "        np.save('time_training.npy', time_training)\n",
    "        np.save('time_actions.npy', time_actions)\n",
    "        np.save('total_time.npy', total_time)\n",
    "        np.save('time_saving.npy', time_saving)\n",
    "        np.save('losses.npy', losses)\n",
    "        \n",
    "        start_time = pygame.time.get_ticks() #Reset the clock\n",
    "     \n",
    "    if not misha_playing:\n",
    "        actions = pygame.key.get_pressed()\n",
    "\n",
    "    update(actions)    \n",
    "        \n",
    "    tick += 1\n",
    "    if not learning:\n",
    "        draw()\n",
    "        pygame.display.flip()\n",
    "        clock.tick(60)\n",
    "    \n",
    "        \n",
    "pygame.display.quit()\n",
    "pygame.quit()\n",
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
